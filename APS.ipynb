{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2 ,f_classif\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\sanil\\Desktop\\aps\\aps_failure_training_set_SMALLER.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(r'C:\\Users\\sanil\\Desktop\\aps\\aps_failure_test_set.csv')\n",
    "df_test.head(10)\n",
    "df_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df.drop('class',axis=1)\n",
    "y_train=df.loc[:,'class']\n",
    "x_test=df_test.drop('class',axis=1)\n",
    "y_test=df_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.replace('neg',0,inplace=True)\n",
    "y_train.replace('pos',1,inplace=True)\n",
    "y_test.replace('neg',0,inplace=True)\n",
    "y_test.replace('pos',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with many na values\n",
    "def drop_na_val(x_train,x_test,*args):\n",
    "    temp1=x_train\n",
    "    temp2=x_test\n",
    "    for column in x_train:\n",
    "        temp_train=x_train[column].value_counts().index.tolist()\n",
    "        temp_test=x_test[column].value_counts().index.tolist()\n",
    "        if 'na' in temp_train and 'na'in temp_test:   \n",
    "            counts1 =temp1[column].value_counts().to_dict()\n",
    "            counts2 =temp2[column].value_counts().to_dict()\n",
    "            if counts1['na']>1000 and counts2['na']>1000:\n",
    "                temp1=temp1.drop(column,axis=1)\n",
    "                temp2=temp2.drop(column,axis=1)\n",
    "    return temp1,temp2           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test=drop_na_val(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_na(x_train,*args):\n",
    "    count=0\n",
    "    for column in x_train:\n",
    "    #x_train[column]=pd.to_numeric(x_train.loc[x_train[column]!='na',column])\n",
    "        temp1=x_train[column].value_counts().index.tolist()\n",
    "        if 'na' in temp1:\n",
    "            count+=1\n",
    "            temp=list(x_train.loc[x_train[column]!='na',column])\n",
    "            temp=list(map(float,temp))\n",
    "            temp=np.array(temp)\n",
    "            #mean=x_train.loc[x_train[column]!='na',column].mean()\n",
    "            mean=np.average(temp)\n",
    "            x_train[column].replace('na',mean,inplace=True)\n",
    "        x_train[column]=pd.to_numeric(x_train[column])\n",
    "    print(\"new number of columns = {0}\".format(count))    \n",
    "    return x_train    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=replace_na(x_train)\n",
    "x_test=replace_na(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.columns=['class']\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization and Standardization (Run only one of the two blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#standardization\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "X=pd.DataFrame(scaler.transform(x_train))\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "X=pd.DataFrame(scaler.transform(x_train))\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Class unbalance histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts=df['class'].value_counts().tolist()\n",
    "sns.set(style=\"darkgrid\")\n",
    "#titanic = sns.load_dataset(\"titanic\")\n",
    "ax = sns.countplot(x=\"class\",data=df,order=df['class'].value_counts().index.tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr=x_train.corr()\n",
    "corr = X.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train = SelectKBest(f_classif, k=30).fit_transform(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train=pd.DataFrame(X_new_train)\n",
    "corr = X_new_train.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_new_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Minority Oversampling technique(Smote) to deal with unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=0,ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit SMOTE and BALANCE CLASSES\n",
    "\n",
    "smote_fit = smote.fit_sample(X,y_train)\n",
    "X_smote= pd.DataFrame(smote_fit[0])\n",
    "Y_smote= pd.DataFrame(smote_fit[1],columns=['class'])\n",
    "aps_train_smote = pd.concat([Y_smote,X_smote],axis=1)\n",
    "temp=x_train.columns\n",
    "aps_train_smote.columns=['class',*temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aps_train_smote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(aps_train_smote[\"class\"])\n",
    "counts=aps_train_smote['class'].value_counts().tolist()\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"class\",data=aps_train_smote,order=aps_train_smote['class'].value_counts().index.tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing test data for classification    0='neg'   1='pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data preparation\n",
    "y=list(Y_smote['class'])\n",
    "y=list(map(int,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing test data \n",
    "scaler.fit(x_test)\n",
    "X_test=pd.DataFrame(scaler.transform(x_test))\n",
    "X_test.head(10)\n",
    "Y_test=list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pca data(optional)\n",
    "pca=PCA(n_components=30)\n",
    "x_train_pca=pca.fit_transform(X_smote)\n",
    "x_test_pca=pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC and AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(actual,predictions,*args):\n",
    "    actual=list(map(int,actual))\n",
    "    predictions=list(map(int,predictions))                                  \n",
    "    fpr, tpr, threshold = roc_curve(actual, predicions) #referenced code for ROC from https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "    roc_auc =auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')                        \n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc) \n",
    "    plt.legend(loc = 'lower right') \n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted error measure 'Cost_1=10  Cost_2=500' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_error(y_true,y_pred):\n",
    "    cnm=confusion_matrix(y_true,y_pred) \n",
    "    error=10*cnm[0][1]+500*cnm[1][0]\n",
    "    print(\"weighted error: {0}\".format(error))\n",
    "    print(\" Total F1 score: {0}\".format(f1_score(y_true,y_pred,average='micro')))\n",
    "    print(\" Positive class F1 score: {0}\".format(f1_score(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnm(y_true,pred):\n",
    "    cnm_matrix=confusion_matrix(y_true,pred) \n",
    "    sns.heatmap(cnm_matrix,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Hyperparameter Optimization using Stratified K fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with PCA\n",
    "param_grid ={'C':[1,3,5],'gamma':np.logspace(-3,3,3)}\n",
    "svm=SVC()\n",
    "grid = GridSearchCV(svm, param_grid, cv=3,scoring='f1_micro',verbose=30)\n",
    "print(\"Done\")\n",
    "grid.fit(x_train_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_x=np.array(X_smote)\n",
    "temp_y=np.array(Y_smote)\n",
    "print(temp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM PCA\n",
    "svm=SVC(C=5,gamma=1)\n",
    "svm.fit(x_train_pca,y)\n",
    "acc=svm.score(x_train_pca,y)\n",
    "pred_train_svm=svm.predict(x_train_pca)\n",
    "print(\"accuracy of training set SVM: {0}\".format(acc))\n",
    "roc(y,pred_train_svm)\n",
    "\n",
    "weighted_error(y,pred_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnm(y,pred_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM TEST PCA\n",
    "acc_test=svm.score(x_test_pca,Y_test)\n",
    "print(\"accuracy of test set SVM: {0}\".format(acc_test))\n",
    "\n",
    "acc=svm.score(x_test_pca,Y_test)\n",
    "pred_test_svm=svm.predict(x_test_pca)\n",
    "print(\"accuracy of training set SVM: {0}\".format(acc))\n",
    "roc(Y_test,pred_test_svm)\n",
    "cnm(Y_test,pred_test_svm)\n",
    "weighted_error(Y_test,pred_test_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM W/O PCA\n",
    "svm=SVC(C=5,gamma=1)\n",
    "svm.fit(X_smote,y)\n",
    "acc=svm.score(X_smote,y)\n",
    "pred_train_svm=svm.predict(X_smote)\n",
    "print(\"accuracy of training set SVM: {0}\".format(acc))\n",
    "roc(y,pred_train_svm)\n",
    "\n",
    "weighted_error(y,pred_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM TEST W/O PCA\n",
    "acc_test=svm.score(X_test,Y_test)\n",
    "print(\"accuracy of test set SVM: {0}\".format(acc_test))\n",
    "\n",
    "acc=svm.score(X_test,Y_test)\n",
    "pred_test_svm=svm.predict(X_test)\n",
    "print(\"accuracy of training set SVM: {0}\".format(acc))\n",
    "roc(Y_test,pred_test_svm)\n",
    "cnm(Y_test,pred_test_svm)\n",
    "weighted_error(Y_test,pred_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB()\n",
    "gnb.fit(X_smote,y)\n",
    "acc=gnb.score(X_smote,y)\n",
    "predictions=gnb.predict(X_smote)\n",
    "roc(y,predictions)\n",
    "print(\"accuracy of Gaussian NB on train set: {0} %\".format(acc*100))\n",
    "\n",
    "cnm_gnb_train=confusion_matrix(y,predictions) \n",
    "sns.heatmap(cnm_gnb_train,annot=True,fmt=\"d\")\n",
    "weighted_error(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_test_acc=gnb.score(X_test,Y_test)\n",
    "gnb_pred_test=gnb.predict(X_test)\n",
    "print(\"accuracy of Gaussian NB on test set: {0} %\".format(gnb_test_acc*100))\n",
    "roc(Y_test,gnb_pred_test)\n",
    "cnm_test=confusion_matrix(Y_test,gnb_pred_test) \n",
    "sns.heatmap(cnm_test,annot=True,fmt=\"d\")\n",
    "weighted_error(Y_test,gnb_pred_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PCA\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(x_train_pca,y)\n",
    "acc=gnb.score(x_train_pca,y)\n",
    "predictions=gnb.predict(x_train_pca)\n",
    "print(\"accuracy of Gaussian NB on train set with pca: {0} %\".format(acc*100))\n",
    "roc(y,predictions)\n",
    "\n",
    "cnm_pca_gnb_train=confusion_matrix(y,predictions) \n",
    "sns.heatmap(cnm_pca_gnb_train,annot=True,fmt=\"d\")\n",
    "\n",
    "weighted_error(y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=gnb.score(x_test_pca,Y_test)\n",
    "predictions=gnb.predict(x_test_pca)\n",
    "print(\"accuracy of Gaussian NB on test set with pca: {0} %\".format(acc*100))\n",
    "\n",
    "roc(Y_test,predictions)\n",
    "\n",
    "cnm_pca_gnb_test=confusion_matrix(Y_test,predictions) \n",
    "sns.heatmap(cnm_pca_gnb_test,annot=True,fmt=\"d\")\n",
    "\n",
    "weighted_error(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "k=[1,2,3,4,5]\n",
    "acc=[]\n",
    "\n",
    "for i in k:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x_train_pca,y, cv=5, scoring='accuracy')\n",
    "    acc.append(scores.mean())\n",
    "print(\"best k:{0}\".format(k[k.index(max(acc))]))\n",
    "print(\"accuracy:{0}\".format(max(acc)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k=[1,2,3,4,5]\n",
    "acc=[]\n",
    "\n",
    "y1=np.array(y)\n",
    "for i in k:\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    temp=np.array([])\n",
    "    for train_index, test_index in skf.split(x_train_pca, y1):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        \n",
    "        X_train_skf, X_test_skf = x_train_pca[train_index], x_train_pca[test_index]\n",
    "        y_train_skf, y_test_skf = y1[train_index], y1[test_index]\n",
    "        knn.fit(X_train_skf,y_train_skf)\n",
    "        temp.append(knn.score(X_test_skf,y_test_skf))\n",
    "    print(\"for k={0} accuracies are {1}\".format(i,temp))    \n",
    "    mean_acc=np.append(np.average(temp))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finiding best k for PCA\n",
    "k=[1,2,3,4,5,6,7,8,9,10]\n",
    "acc=[]\n",
    "\n",
    "for i in k:\n",
    "    knn=KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train_pca,y)\n",
    "    acc.append(knn.score(x_test_pca,Y_test))\n",
    "    print(\"for k={0} accuracy is {1} %\".format(i,knn.score(x_test_pca,Y_test)*100))     \n",
    "print(\"best k: {0}\".format(k[acc.index(max(acc))]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN SET PCA ANALYSIS\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(x_train_pca,y)\n",
    "acc=knn.score(x_train_pca,y)\n",
    "print(\"accuracy of knn on the train set with smote: {0} %\".format(acc*100))\n",
    "knn_pred=knn.predict(x_train_pca)\n",
    "roc(y,knn_pred)\n",
    "\n",
    "cnm_knn_train=confusion_matrix(y,knn_pred) \n",
    "sns.heatmap(cnm_knn_train,annot=True,fmt=\"d\")\n",
    "print(cnm_knn_train)\n",
    "\n",
    "weighted_error(y,knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN PCA TEST SET\n",
    "knn_pred_test=knn.predict(x_test_pca)\n",
    "roc(Y_test,knn_pred_test)\n",
    "\n",
    "cnm_test_knn=confusion_matrix(Y_test,knn_pred_test) \n",
    "sns.heatmap(cnm_test_knn,annot=True,fmt=\"d\")\n",
    "print(cnm_test_knn)\n",
    "\n",
    "weighted_error(Y_test,knn_pred_test)\n",
    "print(\"accuracy of knn on the test set with PCA: {0} %\".format(knn.score(x_test_pca,Y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN WITHOUT PCA\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_smote,y)\n",
    "acc=knn.score(X_smote,y)\n",
    "print(\"accuracy of knn on the train set with smote: {0} %\".format(acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN ANALYSIS WITHOUT PCA\n",
    "knn_pred=knn.predict(X_smote)\n",
    "roc(y,knn_pred)\n",
    "\n",
    "cnm_knn_train=confusion_matrix(y,knn_pred) \n",
    "sns.heatmap(cnm_knn_train,annot=True,fmt=\"d\")\n",
    "print(cnm_knn_train)\n",
    "\n",
    "weighted_error(y,knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN TEST WITHOUT PCA\n",
    "knn_pred_test=knn.predict(X_test)\n",
    "roc(Y_test,knn_pred_test)\n",
    "\n",
    "cnm_test_knn=confusion_matrix(Y_test,knn_pred_test) \n",
    "sns.heatmap(cnm_test_knn,annot=True,fmt=\"d\")\n",
    "print(cnm_test_knn)\n",
    "print(\"accuracy: {0}\".format(knn.score(X_test,Y_test)))\n",
    "weighted_error(Y_test,knn_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=list(map(int,knn_pred_test))\n",
    "print(\"F1 score for the test set is: {0}\".format(f1_score(Y_test,temp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={'n_estimators':[20,40,60,80,100],'max_depth':[1,2,3,4,5]}\n",
    "rf=RandomForestClassifier()\n",
    "grid = GridSearchCV(rf, param_grid, cv=5,scoring='f1_micro',verbose=10)\n",
    "print(\"Done\")\n",
    "grid.fit(x_train_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=40, max_depth=5,random_state=0)\n",
    "rf.fit(X_smote,y)\n",
    "acc_rf_train=rf.score(X_smote,y)\n",
    "print(\"accuracy of Random Forest on the train set with smote: {0} %\".format(acc_rf_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_train=rf.predict(X_smote)\n",
    "roc(y,rf_pred_train)\n",
    "\n",
    "cnm_train_rf=confusion_matrix(y,rf_pred_train) \n",
    "sns.heatmap(cnm_train_rf,annot=True,fmt=\"d\")\n",
    "print(cnm_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test_rf=rf.predict(X_test)\n",
    "roc(Y_test,pred_test_rf)\n",
    "\n",
    "cnm_test_rf=confusion_matrix(Y_test,pred_test_rf) \n",
    "sns.heatmap(cnm_test_rf,annot=True,fmt=\"d\")\n",
    "print(\"accuracy of Random Forest test set : {0} %\".format(rf.score(X_test,Y_test)*100))\n",
    "weighted_error(Y_test,pred_test_rf)\n",
    "print(cnm_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITH PCA\n",
    "rf=RandomForestClassifier(n_estimators=40, max_depth=5,random_state=0)\n",
    "rf.fit(x_train_pca,y)\n",
    "acc_rf_train=rf.score(x_train_pca,y)\n",
    "print(\"accuracy of Random Forest on the train set with smote: {0} %\".format(acc_rf_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PCA\n",
    "rf_pred_train=rf.predict(x_train_pca)\n",
    "roc(y,rf_pred_train)\n",
    "cnm(y,rf_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test_rf=rf.predict(x_test_pca)\n",
    "roc(Y_test,pred_test_rf)\n",
    "print(\"accuracy of Random Forest on the test set pca: {0} %\".format(rf.score(x_test_pca,Y_test)*100))\n",
    "cnm_test_rf=confusion_matrix(Y_test,pred_test_rf) \n",
    "sns.heatmap(cnm_test_rf,annot=True,fmt=\"d\")\n",
    "weighted_error(Y_test,pred_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={'alpha':[0.0001,0.001,0.01,0.1,1],'eta0':[0.001,0.01,0.1,1,10]}\n",
    "clf=Perceptron(shuffle=True)\n",
    "grid = GridSearchCV(clf, param_grid, cv=3,scoring='f1_micro',verbose=30)\n",
    "print(\"Done\")\n",
    "grid.fit(x_train_pca,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERCEPTRON WITH PCA\n",
    "clf=Perceptron(alpha=0.0001,eta0=0.001,shuffle=True)\n",
    "clf.fit(x_train_pca,y)\n",
    "acc=clf.score(x_train_pca,y)\n",
    "print(\"accuracy of perceptron on the train set with pca: {0} %\".format(acc*100))\n",
    "pred=clf.predict(x_train_pca)\n",
    "roc(y,pred)\n",
    "cnm(y,pred)\n",
    "weighted_error(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test PCA\n",
    "pred_test=clf.predict(x_test_pca)\n",
    "acc=clf.score(x_test_pca,Y_test)\n",
    "print(\"accuracy of perceptron on the test set with pca: {0} %\".format(acc*100))\n",
    "roc(Y_test,pred_test)\n",
    "cnm(Y_test,pred_test)\n",
    "weighted_error(Y_test,pred_test)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERCEPTRON WITHOUT PCA\n",
    "clf=Perceptron(alpha=0.0001,eta0=0.001,shuffle=True)\n",
    "clf.fit(X_smote,y)\n",
    "acc=clf.score(X_smote,y)\n",
    "print(\"accuracy of perceptron on the train set without pca: {0} %\".format(acc*100))\n",
    "pred=clf.predict(X_smote)\n",
    "roc(y,pred)\n",
    "cnm(y,pred)\n",
    "weighted_error(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PCA\n",
    "pred_test=clf.predict(X_test)\n",
    "acc=clf.score(X_test,Y_test)\n",
    "print(\"accuracy of perceptron on the test set without pca: {0} %\".format(acc*100))\n",
    "roc(Y_test,pred_test)\n",
    "cnm(Y_test,pred_test)\n",
    "weighted_error(Y_test,pred_test)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
